//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-22781540
// Cuda compilation tools, release 9.0, V9.0.176
// Based on LLVM 3.4svn
//

.version 6.0
.target sm_30
.address_size 64

	// .globl	_Z9intersecti
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 vertex_buffer[1];
.global .align 1 .b8 index_buffer[1];
.global .align 1 .b8 texcoord_buffer[1];
.global .align 4 .b8 hit_attr[12];
.global .align 4 .b8 ray[36];
.global .align 4 .b8 hit_prd[12];
.global .texref mask_sampler;
.global .align 4 .u32 launch_index;
.global .align 4 .b8 top_object[4];
.global .align 1 .b8 hits[1];
.global .align 1 .b8 rays[1];
.global .align 4 .b8 _ZN21rti_internal_typeinfo8hit_attrE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3rayE[8] = {82, 97, 121, 0, 36, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo7hit_prdE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo12launch_indexE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10top_objectE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;
.global .align 4 .b8 _ZN21rti_internal_typename8hit_attrE[4] = {72, 105, 116, 0};
.global .align 16 .b8 _ZN21rti_internal_typename3rayE[11] = {111, 112, 116, 105, 120, 58, 58, 82, 97, 121, 0};
.global .align 4 .b8 _ZN21rti_internal_typename7hit_prdE[4] = {72, 105, 116, 0};
.global .align 16 .b8 _ZN21rti_internal_typename12launch_indexE[13] = {117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 0};
.global .align 16 .b8 _ZN21rti_internal_typename10top_objectE[9] = {114, 116, 79, 98, 106, 101, 99, 116, 0};
.global .align 4 .u32 _ZN21rti_internal_typeenum8hit_attrE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3rayE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum7hit_prdE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum12launch_indexE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10top_objectE = 4919;
.global .align 16 .b8 _ZN21rti_internal_semantic8hit_attrE[19] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 104, 105, 116, 95, 97, 116, 116, 114, 0};
.global .align 16 .b8 _ZN21rti_internal_semantic3rayE[13] = {114, 116, 67, 117, 114, 114, 101, 110, 116, 82, 97, 121, 0};
.global .align 16 .b8 _ZN21rti_internal_semantic7hit_prdE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 16 .b8 _ZN21rti_internal_semantic12launch_indexE[14] = {114, 116, 76, 97, 117, 110, 99, 104, 73, 110, 100, 101, 120, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic10top_objectE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8hit_attrE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3rayE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation7hit_prdE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation12launch_indexE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10top_objectE[1];
.global .align 16 .b8 $str[44] = {67, 97, 117, 103, 104, 116, 32, 101, 120, 99, 101, 112, 116, 105, 111, 110, 32, 48, 120, 37, 88, 32, 97, 116, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 40, 37, 100, 41, 10, 0};

.visible .entry _Z9intersecti(
	.param .u32 _Z9intersecti_param_0
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<63>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<27>;


	ld.param.u32 	%r1, [_Z9intersecti_param_0];
	cvt.s64.s32	%rd3, %r1;
	mov.u64 	%rd25, index_buffer;
	cvta.global.u64 	%rd2, %rd25;
	mov.u32 	%r8, 1;
	mov.u32 	%r9, 12;
	mov.u64 	%rd24, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r8, %r9, %rd3, %rd24, %rd24, %rd24);
	// inline asm
	ld.s32 	%rd9, [%rd1];
	mov.u64 	%rd26, vertex_buffer;
	cvta.global.u64 	%rd8, %rd26;
	ld.s32 	%rd15, [%rd1+4];
	ld.s32 	%rd21, [%rd1+8];
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd8, %r8, %r9, %rd9, %rd24, %rd24, %rd24);
	// inline asm
	ld.f32 	%f2, [%rd7+8];
	ld.f32 	%f3, [%rd7+4];
	ld.f32 	%f4, [%rd7];
	// inline asm
	call (%rd13), _rt_buffer_get_64, (%rd8, %r8, %r9, %rd15, %rd24, %rd24, %rd24);
	// inline asm
	ld.f32 	%f5, [%rd13+8];
	ld.f32 	%f6, [%rd13+4];
	ld.f32 	%f7, [%rd13];
	// inline asm
	call (%rd19), _rt_buffer_get_64, (%rd8, %r8, %r9, %rd21, %rd24, %rd24, %rd24);
	// inline asm
	sub.ftz.f32 	%f8, %f7, %f4;
	sub.ftz.f32 	%f9, %f6, %f3;
	sub.ftz.f32 	%f10, %f5, %f2;
	ld.f32 	%f11, [%rd19+8];
	ld.f32 	%f12, [%rd19+4];
	ld.f32 	%f13, [%rd19];
	sub.ftz.f32 	%f14, %f4, %f13;
	sub.ftz.f32 	%f15, %f3, %f12;
	sub.ftz.f32 	%f16, %f2, %f11;
	mul.ftz.f32 	%f17, %f10, %f15;
	mul.ftz.f32 	%f18, %f9, %f16;
	sub.ftz.f32 	%f19, %f17, %f18;
	mul.ftz.f32 	%f20, %f8, %f16;
	mul.ftz.f32 	%f21, %f10, %f14;
	sub.ftz.f32 	%f22, %f20, %f21;
	mul.ftz.f32 	%f23, %f9, %f14;
	mul.ftz.f32 	%f24, %f8, %f15;
	sub.ftz.f32 	%f25, %f23, %f24;
	ld.global.f32 	%f26, [ray+12];
	ld.global.f32 	%f27, [ray+16];
	mul.ftz.f32 	%f28, %f27, %f22;
	fma.rn.ftz.f32 	%f29, %f26, %f19, %f28;
	ld.global.f32 	%f30, [ray+20];
	fma.rn.ftz.f32 	%f31, %f30, %f25, %f29;
	rcp.approx.ftz.f32 	%f32, %f31;
	ld.global.f32 	%f33, [ray];
	sub.ftz.f32 	%f34, %f4, %f33;
	ld.global.f32 	%f35, [ray+4];
	sub.ftz.f32 	%f36, %f3, %f35;
	ld.global.f32 	%f37, [ray+8];
	sub.ftz.f32 	%f38, %f2, %f37;
	mul.ftz.f32 	%f39, %f32, %f34;
	mul.ftz.f32 	%f40, %f32, %f36;
	mul.ftz.f32 	%f41, %f32, %f38;
	mul.ftz.f32 	%f42, %f27, %f41;
	mul.ftz.f32 	%f43, %f40, %f30;
	sub.ftz.f32 	%f44, %f42, %f43;
	mul.ftz.f32 	%f45, %f39, %f30;
	mul.ftz.f32 	%f46, %f41, %f26;
	sub.ftz.f32 	%f47, %f45, %f46;
	mul.ftz.f32 	%f48, %f40, %f26;
	mul.ftz.f32 	%f49, %f39, %f27;
	sub.ftz.f32 	%f50, %f48, %f49;
	mul.ftz.f32 	%f51, %f15, %f47;
	fma.rn.ftz.f32 	%f52, %f14, %f44, %f51;
	fma.rn.ftz.f32 	%f53, %f16, %f50, %f52;
	mul.ftz.f32 	%f54, %f9, %f47;
	fma.rn.ftz.f32 	%f55, %f8, %f44, %f54;
	fma.rn.ftz.f32 	%f56, %f10, %f50, %f55;
	mul.ftz.f32 	%f57, %f22, %f40;
	fma.rn.ftz.f32 	%f58, %f19, %f39, %f57;
	fma.rn.ftz.f32 	%f1, %f25, %f41, %f58;
	ld.global.f32 	%f59, [ray+32];
	setp.lt.ftz.f32	%p1, %f1, %f59;
	ld.global.f32 	%f60, [ray+28];
	setp.gt.ftz.f32	%p2, %f1, %f60;
	and.pred  	%p3, %p1, %p2;
	setp.ge.ftz.f32	%p4, %f53, 0f00000000;
	and.pred  	%p5, %p3, %p4;
	setp.ge.ftz.f32	%p6, %f56, 0f00000000;
	and.pred  	%p7, %p5, %p6;
	add.ftz.f32 	%f61, %f53, %f56;
	setp.le.ftz.f32	%p8, %f61, 0f3F800000;
	and.pred  	%p9, %p7, %p8;
	@!%p9 bra 	BB0_3;
	bra.uni 	BB0_1;

BB0_1:
	// inline asm
	call (%r10), _rt_potential_intersection, (%f1);
	// inline asm
	setp.eq.s32	%p10, %r10, 0;
	@%p10 bra 	BB0_3;

	st.global.f32 	[hit_attr], %f1;
	st.global.u32 	[hit_attr+8], %r1;
	mov.u32 	%r12, 0;
	// inline asm
	call (%r11), _rt_report_intersection, (%r12);
	// inline asm

BB0_3:
	ret;
}

	// .globl	_Z6boundsiPf
.visible .entry _Z6boundsiPf(
	.param .u32 _Z6boundsiPf_param_0,
	.param .u64 _Z6boundsiPf_param_1
)
{
	.reg .f32 	%f<22>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<29>;


	ld.param.u64 	%rd25, [_Z6boundsiPf_param_1];
	ld.param.s32 	%rd3, [_Z6boundsiPf_param_0];
	mov.u64 	%rd26, index_buffer;
	cvta.global.u64 	%rd2, %rd26;
	mov.u32 	%r7, 1;
	mov.u32 	%r8, 12;
	mov.u64 	%rd24, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r7, %r8, %rd3, %rd24, %rd24, %rd24);
	// inline asm
	ld.s32 	%rd9, [%rd1];
	mov.u64 	%rd27, vertex_buffer;
	cvta.global.u64 	%rd8, %rd27;
	ld.s32 	%rd15, [%rd1+4];
	ld.s32 	%rd21, [%rd1+8];
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd8, %r7, %r8, %rd9, %rd24, %rd24, %rd24);
	// inline asm
	ld.f32 	%f1, [%rd7+8];
	ld.f32 	%f2, [%rd7+4];
	ld.f32 	%f3, [%rd7];
	// inline asm
	call (%rd13), _rt_buffer_get_64, (%rd8, %r7, %r8, %rd15, %rd24, %rd24, %rd24);
	// inline asm
	ld.f32 	%f4, [%rd13+8];
	ld.f32 	%f5, [%rd13+4];
	ld.f32 	%f6, [%rd13];
	// inline asm
	call (%rd19), _rt_buffer_get_64, (%rd8, %r7, %r8, %rd21, %rd24, %rd24, %rd24);
	// inline asm
	ld.f32 	%f7, [%rd19+8];
	ld.f32 	%f8, [%rd19+4];
	ld.f32 	%f9, [%rd19];
	cvta.to.global.u64 	%rd28, %rd25;
	min.ftz.f32 	%f10, %f3, %f6;
	min.ftz.f32 	%f11, %f2, %f5;
	min.ftz.f32 	%f12, %f1, %f4;
	min.ftz.f32 	%f13, %f10, %f9;
	min.ftz.f32 	%f14, %f11, %f8;
	min.ftz.f32 	%f15, %f12, %f7;
	st.global.f32 	[%rd28], %f13;
	st.global.f32 	[%rd28+4], %f14;
	st.global.f32 	[%rd28+8], %f15;
	max.ftz.f32 	%f16, %f3, %f6;
	max.ftz.f32 	%f17, %f2, %f5;
	max.ftz.f32 	%f18, %f1, %f4;
	max.ftz.f32 	%f19, %f16, %f9;
	max.ftz.f32 	%f20, %f17, %f8;
	max.ftz.f32 	%f21, %f18, %f7;
	st.global.f32 	[%rd28+12], %f19;
	st.global.f32 	[%rd28+16], %f20;
	st.global.f32 	[%rd28+20], %f21;
	ret;
}

	// .globl	_Z11closest_hitv
.visible .entry _Z11closest_hitv(

)
{
	.reg .f32 	%f<3>;
	.reg .b32 	%r<2>;


	ld.global.f32 	%f1, [hit_attr];
	ld.global.f32 	%f2, [hit_attr+4];
	ld.global.u32 	%r1, [hit_attr+8];
	st.global.u32 	[hit_prd+8], %r1;
	st.global.f32 	[hit_prd+4], %f2;
	st.global.f32 	[hit_prd], %f1;
	ret;
}

	// .globl	_Z7any_hitv
.visible .entry _Z7any_hitv(

)
{



	ret;
}

	// .globl	_Z7ray_genv
.visible .entry _Z7ray_genv(

)
{
	.local .align 4 .b8 	__local_depot4[12];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<11>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<18>;


	mov.u64 	%rd17, __local_depot4;
	cvta.local.u64 	%SP, %rd17;
	add.u64 	%rd7, %SP, 0;
	cvta.to.local.u64 	%rd14, %rd7;
	mov.u32 	%r8, -1082130432;
	st.local.u32 	[%rd14], %r8;
	mov.u32 	%r9, -1;
	st.local.u32 	[%rd14+8], %r9;
	ld.global.u32 	%rd3, [launch_index];
	mov.u64 	%rd15, rays;
	cvta.global.u64 	%rd2, %rd15;
	mov.u32 	%r6, 1;
	mov.u32 	%r2, 32;
	mov.u64 	%rd13, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r6, %r2, %rd3, %rd13, %rd13, %rd13);
	// inline asm
	ld.f32 	%f8, [%rd1+28];
	ld.f32 	%f6, [%rd1+24];
	ld.f32 	%f5, [%rd1+20];
	ld.f32 	%f4, [%rd1+16];
	ld.f32 	%f7, [%rd1+12];
	ld.f32 	%f3, [%rd1+8];
	ld.f32 	%f2, [%rd1+4];
	ld.f32 	%f1, [%rd1];
	ld.global.u32 	%r3, [top_object];
	mov.u32 	%r4, 0;
	mov.u32 	%r7, 12;
	// inline asm
	call _rt_trace_64, (%r3, %f1, %f2, %f3, %f4, %f5, %f6, %r4, %f7, %f8, %rd7, %r7);
	// inline asm
	st.local.f32 	[%rd14+4], %f8;
	ld.global.u32 	%rd10, [launch_index];
	mov.u64 	%rd16, hits;
	cvta.global.u64 	%rd9, %rd16;
	// inline asm
	call (%rd8), _rt_buffer_get_64, (%rd9, %r6, %r7, %rd10, %rd13, %rd13, %rd13);
	// inline asm
	ld.local.f32 	%f9, [%rd14];
	ld.local.f32 	%f10, [%rd14+4];
	ld.local.u32 	%r10, [%rd14+8];
	st.u32 	[%rd8+8], %r10;
	st.f32 	[%rd8+4], %f10;
	st.f32 	[%rd8], %f9;
	ret;
}

	// .globl	_Z9exceptionv
.visible .entry _Z9exceptionv(

)
{
	.local .align 8 .b8 	__local_depot5[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<13>;


	mov.u64 	%rd12, __local_depot5;
	cvta.local.u64 	%SP, %rd12;
	// inline asm
	call (%r3), _rt_get_exception_code, ();
	// inline asm
	ld.global.u32 	%r2, [launch_index];
	// inline asm
	call (%r4), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p1, %r4, 0;
	@%p1 bra 	BB5_2;

	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.v2.u32 	[%rd2], {%r3, %r2};
	mov.u64 	%rd3, $str;
	cvta.global.u64 	%rd4, %rd3;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r5, [retval0+0];
	
	//{
	}// Callseq End 0

BB5_2:
	ld.global.u32 	%rd7, [launch_index];
	mov.u64 	%rd11, hits;
	cvta.global.u64 	%rd6, %rd11;
	mov.u32 	%r6, 1;
	mov.u32 	%r7, 12;
	mov.u64 	%rd10, 0;
	// inline asm
	call (%rd5), _rt_buffer_get_64, (%rd6, %r6, %r7, %rd7, %rd10, %rd10, %rd10);
	// inline asm
	mov.u32 	%r8, -1;
	st.u32 	[%rd5+8], %r8;
	mov.u32 	%r9, -1082130432;
	st.u32 	[%rd5], %r9;
	ret;
}


